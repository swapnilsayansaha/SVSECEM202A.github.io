<!DOCTYPE html>
<html lang="en">
	<head>
		<title>Materials and Methods - MREarable - Integrating Spatial Audio in a Mixed Reality Environment through Earable Sensor Modalities</title>


<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

		
		<link id="wsite-base-style" rel="stylesheet" type="text/css" href="http://cdn2.editmysite.com/css/sites.css?buildTime=1234" />
<link rel="stylesheet" type="text/css" href="http://cdn2.editmysite.com/css/old/fancybox.css?1234" />
<link rel="stylesheet" type="text/css" href="http://cdn2.editmysite.com/css/social-icons.css?buildtime=1234" media="screen,projection" />
<link rel="stylesheet" type="text/css" href="files/main_style.css?1574891290" title="wsite-theme-css" />

<link href='http://fonts.googleapis.com/css?family=Amaranth:400,700,400italic,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<link href='http://fonts.googleapis.com/css?family=Amaranth:400,700,400italic,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<link href='http://fonts.googleapis.com/css?family=Amaranth:400,700,400italic,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<link href='http://fonts.googleapis.com/css?family=Amaranth:400,700,400italic,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<link href='http://fonts.googleapis.com/css?family=Amaranth:400,700,400italic,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<link href='http://fonts.googleapis.com/css?family=Amaranth:400,700,400italic,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic&subset=latin,latin-ext' rel='stylesheet' type='text/css' />
<style type='text/css'>
.wsite-elements.wsite-not-footer:not(.wsite-header-elements) div.paragraph, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) p, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-block .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-description, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .wsite-form-field label, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .wsite-form-field label, #wsite-content div.paragraph, #wsite-content p, #wsite-content .product-block .product-title, #wsite-content .product-description, #wsite-content .wsite-form-field label, #wsite-content .wsite-form-field label, .blog-sidebar div.paragraph, .blog-sidebar p, .blog-sidebar .wsite-form-field label, .blog-sidebar .wsite-form-field label {font-family:"Amaranth" !important;}
#wsite-content div.paragraph, #wsite-content p, #wsite-content .product-block .product-title, #wsite-content .product-description, #wsite-content .wsite-form-field label, #wsite-content .wsite-form-field label, .blog-sidebar div.paragraph, .blog-sidebar p, .blog-sidebar .wsite-form-field label, .blog-sidebar .wsite-form-field label {color:#2a2a2a !important;}
.wsite-elements.wsite-footer div.paragraph, .wsite-elements.wsite-footer p, .wsite-elements.wsite-footer .product-block .product-title, .wsite-elements.wsite-footer .product-description, .wsite-elements.wsite-footer .wsite-form-field label, .wsite-elements.wsite-footer .wsite-form-field label{font-family:"Montserrat" !important;}
.wsite-elements.wsite-not-footer:not(.wsite-header-elements) h2, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-long .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-large .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-small .product-title, #wsite-content h2, #wsite-content .product-long .product-title, #wsite-content .product-large .product-title, #wsite-content .product-small .product-title, .blog-sidebar h2 {font-family:"Amaranth" !important;letter-spacing: 0px !important;}
#wsite-content h2, #wsite-content .product-long .product-title, #wsite-content .product-large .product-title, #wsite-content .product-small .product-title, .blog-sidebar h2 {}
.wsite-elements.wsite-footer h2, .wsite-elements.wsite-footer .product-long .product-title, .wsite-elements.wsite-footer .product-large .product-title, .wsite-elements.wsite-footer .product-small .product-title{font-family:"Montserrat" !important;font-weight:400 !important;}
#wsite-title {font-family:"Amaranth" !important;font-style:normal !important;text-transform:  none !important;letter-spacing: 0px !important;}
.wsite-menu-default a {font-family:"Amaranth" !important;}
.wsite-menu a {}
.wsite-image div, .wsite-caption {}
.galleryCaptionInnerText {}
.fancybox-title {}
.wslide-caption-text {}
.wsite-phone {}
.wsite-headline,.wsite-header-section .wsite-content-title {font-family:"Amaranth" !important;letter-spacing: 1px !important;}
.wsite-headline-paragraph,.wsite-header-section .paragraph {font-family:"Amaranth" !important;color:#2a2a2a !important;text-transform:  none !important;letter-spacing: 0px !important;}
.wsite-button-inner {}
.wsite-not-footer blockquote {font-family:"Lora" !important;}
.wsite-footer blockquote {}
.blog-header h2 a {}
#wsite-content h2.wsite-product-title {}
.wsite-product .wsite-product-price a {}
@media screen and (min-width: 767px) {.wsite-elements.wsite-not-footer:not(.wsite-header-elements) div.paragraph, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) p, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-block .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-description, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .wsite-form-field label, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .wsite-form-field label, #wsite-content div.paragraph, #wsite-content p, #wsite-content .product-block .product-title, #wsite-content .product-description, #wsite-content .wsite-form-field label, #wsite-content .wsite-form-field label, .blog-sidebar div.paragraph, .blog-sidebar p, .blog-sidebar .wsite-form-field label, .blog-sidebar .wsite-form-field label {font-size:18px !important;line-height:17px !important;}
#wsite-content div.paragraph, #wsite-content p, #wsite-content .product-block .product-title, #wsite-content .product-description, #wsite-content .wsite-form-field label, #wsite-content .wsite-form-field label, .blog-sidebar div.paragraph, .blog-sidebar p, .blog-sidebar .wsite-form-field label, .blog-sidebar .wsite-form-field label {}
.wsite-elements.wsite-footer div.paragraph, .wsite-elements.wsite-footer p, .wsite-elements.wsite-footer .product-block .product-title, .wsite-elements.wsite-footer .product-description, .wsite-elements.wsite-footer .wsite-form-field label, .wsite-elements.wsite-footer .wsite-form-field label{font-size:13px !important;}
.wsite-elements.wsite-not-footer:not(.wsite-header-elements) h2, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-long .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-large .product-title, .wsite-elements.wsite-not-footer:not(.wsite-header-elements) .product-small .product-title, #wsite-content h2, #wsite-content .product-long .product-title, #wsite-content .product-large .product-title, #wsite-content .product-small .product-title, .blog-sidebar h2 {font-size:30px !important;line-height:6px !important;}
#wsite-content h2, #wsite-content .product-long .product-title, #wsite-content .product-large .product-title, #wsite-content .product-small .product-title, .blog-sidebar h2 {}
.wsite-elements.wsite-footer h2, .wsite-elements.wsite-footer .product-long .product-title, .wsite-elements.wsite-footer .product-large .product-title, .wsite-elements.wsite-footer .product-small .product-title{font-size:11px !important;}
#wsite-title {font-size:17px !important;}
.wsite-menu-default a {}
.wsite-menu a {}
.wsite-image div, .wsite-caption {}
.galleryCaptionInnerText {}
.fancybox-title {}
.wslide-caption-text {}
.wsite-phone {}
.wsite-headline,.wsite-header-section .wsite-content-title {font-size:90px !important;line-height:25px !important;}
.wsite-headline-paragraph,.wsite-header-section .paragraph {font-size:22px !important;line-height:20px !important;}
.wsite-button-inner {}
.wsite-not-footer blockquote {font-size:30px !important;}
.wsite-footer blockquote {}
.blog-header h2 a {}
#wsite-content h2.wsite-product-title {}
.wsite-product .wsite-product-price a {}
}</style>

		<script>
var STATIC_BASE = '//cdn1.editmysite.com/';
var ASSETS_BASE = '//cdn2.editmysite.com/';
var STYLE_PREFIX = 'wsite';
</script>
<script src='https://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js'></script>

<script type="text/javascript" src="http://cdn2.editmysite.com/js/lang/en/stl.js?buildTime=1234&"></script>
<script src="http://cdn2.editmysite.com/js/site/main.js?buildTime=1234"></script><script type="text/javascript">
		function initCustomerAccountsModels() {
					(function(){_W.setup_rpc({"url":"\/ajax\/api\/JsonRPC\/CustomerAccounts\/","actions":{"CustomerAccounts":[{"name":"login","len":2,"multiple":false,"standalone":false},{"name":"logout","len":0,"multiple":false,"standalone":false},{"name":"getSessionDetails","len":0,"multiple":false,"standalone":false},{"name":"getAccountDetails","len":0,"multiple":false,"standalone":false},{"name":"getOrders","len":0,"multiple":false,"standalone":false},{"name":"register","len":4,"multiple":false,"standalone":false},{"name":"emailExists","len":1,"multiple":false,"standalone":false},{"name":"passwordReset","len":1,"multiple":false,"standalone":false},{"name":"passwordUpdate","len":3,"multiple":false,"standalone":false},{"name":"validateSession","len":1,"multiple":false,"standalone":false}]},"namespace":"_W.CustomerAccounts.RPC"});
_W.setup_model_rpc({"rpc_namespace":"_W.CustomerAccounts.RPC","model_namespace":"_W.CustomerAccounts.BackboneModelData","collection_namespace":"_W.CustomerAccounts.BackboneCollectionData","bootstrap_namespace":"_W.CustomerAccounts.BackboneBootstrap","models":{"CustomerAccounts":{"_class":"CustomerAccounts.Model.CustomerAccounts","defaults":null,"validation":null,"types":null,"idAttribute":null,"keydefs":null}},"collections":{"CustomerAccounts":{"_class":"CustomerAccounts.Collection.CustomerAccounts"}},"bootstrap":[]});
})();
		}
		if(document.createEvent && document.addEventListener) {
			var initEvt = document.createEvent('Event');
			initEvt.initEvent('customerAccountsModelsInitialized', true, false);
			document.dispatchEvent(initEvt);
		} else if(document.documentElement.initCustomerAccountsModels === 0){
			document.documentElement.initCustomerAccountsModels++
		}
		</script>
		<script type="text/javascript"> _W = _W || {}; _W.securePrefix='UNSET'; </script><script>_W = _W || {};
			_W.customerLocale = "en_US";
			_W.storeName = null;
			_W.storeCountry = "US";
			_W.storeCurrency = "USD";
			_W.storeEuPrivacyPolicyUrl = "";
			com_currentSite = "530359163563960245";
			com_userID = "48611635";</script><script type="text/javascript">_W.configDomain = "www.weebly.com";</script><script>_W.relinquish && _W.relinquish()</script>
<script type="text/javascript" src="http://cdn2.editmysite.com/js/lang/en/stl.js?buildTime=1234&"></script><script> _W.themePlugins = [];</script><script type="text/javascript"> _W.recaptchaUrl = "https://www.google.com/recaptcha/api.js"; </script><script type="text/javascript"><!--
	var IS_ARCHIVE = 1;
	var DISABLE_NAV_MORE = 1;
	function initFlyouts(){
		initPublishedFlyoutMenus(
			[{"id":"882454809154185041","title":"Project Abstract","url":"project-abstract.html","target":"","nav_menu":false,"nonclickable":false},{"id":"249509689683143900","title":"Materials and Methods","url":"materials-and-methods.html","target":"","nav_menu":false,"nonclickable":false},{"id":"990999752696982730","title":"Results","url":"results.html","target":"","nav_menu":false,"nonclickable":false},{"id":"595281588527961028","title":"Conclusion and Future Work","url":"conclusion-and-future-work.html","target":"","nav_menu":false,"nonclickable":false},{"id":"905329364918407754","title":"Related Work","url":"related-work.html","target":"","nav_menu":false,"nonclickable":false},{"id":"500750823166447332","title":"References","url":"references.html","target":"","nav_menu":false,"nonclickable":false}],
			"249509689683143900",
			'',
			'active',
			false,
			{"navigation\/item":"<li {{#id}}id=\"{{id}}\"{{\/id}} class=\"wsite-menu-item-wrap\">\n\t<a\n\t\t{{^nonclickable}}\n\t\t\t{{^nav_menu}}\n\t\t\t\thref=\"{{url}}\"\n\t\t\t{{\/nav_menu}}\n\t\t{{\/nonclickable}}\n\t\t{{#target}}\n\t\t\ttarget=\"{{target}}\"\n\t\t{{\/target}}\n\t\t{{#membership_required}}\n\t\t\tdata-membership-required=\"{{.}}\"\n\t\t{{\/membership_required}}\n\t\tclass=\"wsite-menu-item\"\n\t\t>\n\t\t{{{title_html}}}\n\t<\/a>\n\t{{#has_children}}{{> navigation\/flyout\/list}}{{\/has_children}}\n<\/li>\n","navigation\/flyout\/list":"<div class=\"wsite-menu-wrap\" style=\"display:none\">\n\t<ul class=\"wsite-menu\">\n\t\t{{#children}}{{> navigation\/flyout\/item}}{{\/children}}\n\t<\/ul>\n<\/div>\n","navigation\/flyout\/item":"<li {{#id}}id=\"{{id}}\"{{\/id}}\n\tclass=\"wsite-menu-subitem-wrap {{#is_current}}wsite-nav-current{{\/is_current}}\"\n\t>\n\t<a\n\t\t{{^nonclickable}}\n\t\t\t{{^nav_menu}}\n\t\t\t\thref=\"{{url}}\"\n\t\t\t{{\/nav_menu}}\n\t\t{{\/nonclickable}}\n\t\t{{#target}}\n\t\t\ttarget=\"{{target}}\"\n\t\t{{\/target}}\n\t\tclass=\"wsite-menu-subitem\"\n\t\t>\n\t\t<span class=\"wsite-menu-title\">\n\t\t\t{{{title_html}}}\n\t\t<\/span>{{#has_children}}<span class=\"wsite-menu-arrow\">&gt;<\/span>{{\/has_children}}\n\t<\/a>\n\t{{#has_children}}{{> navigation\/flyout\/list}}{{\/has_children}}\n<\/li>\n"},
			{"hasCustomMembership":true,"hasCustomMinicart":true}
		)
	}
//-->
</script>
		
		
	</head>
	<body class="header-page  wsite-page-materials-and-methods  sticky-nav-on full-width-on header-scroll-animate-off  wsite-theme-light"><div class="wrapper">
    <div class="unite-header">
      <div class="nav-wrap">
        <div class="container">
          <a class="hamburger" aria-label="Menu" href="#"><span></span></a>
          <div class="logo"><span class="wsite-logo">

	<a href="">
	
	<span id="wsite-title">MREarable - Integrating Spatial Audio in a Mixed Reality Environment through Earable Sensor Modalities</span>
	
	</a>

</span></div>
          <div class="nav desktop-nav"><ul class="wsite-menu-default">
		<li id="pg882454809154185041" class="wsite-menu-item-wrap">
			<a
						href="project-abstract.html"
				class="wsite-menu-item"
				>
				Project Abstract
			</a>
			
		</li>
		<li id="active" class="wsite-menu-item-wrap">
			<a
						href="materials-and-methods.html"
				class="wsite-menu-item"
				>
				Materials and Methods
			</a>
			
		</li>
		<li id="pg990999752696982730" class="wsite-menu-item-wrap">
			<a
						href="results.html"
				class="wsite-menu-item"
				>
				Results
			</a>
			
		</li>
		<li id="pg595281588527961028" class="wsite-menu-item-wrap">
			<a
						href="conclusion-and-future-work.html"
				class="wsite-menu-item"
				>
				Conclusion and Future Work
			</a>
			
		</li>
		<li id="pg905329364918407754" class="wsite-menu-item-wrap">
			<a
						href="related-work.html"
				class="wsite-menu-item"
				>
				Related Work
			</a>
			
		</li>
		<li id="pg500750823166447332" class="wsite-menu-item-wrap">
			<a
						href="references.html"
				class="wsite-menu-item"
				>
				References
			</a>
			
		</li>
</ul>
</div>
          <div class="nav membership-cart"><span id="member-login" class="wsite-custom-membership-wrapper"><a href="#" id="wsite-nav-login-a"></a></span></div>
        </div>
      </div>
    </div>

    <div class="banner-wrap">
      <div class="wsite-elements wsite-not-footer wsite-header-elements">
	<div class="wsite-section-wrap">
	<div  class="wsite-section wsite-header-section wsite-section-bg-color wsite-section-effect-reveal" style="height: auto;background-color: #faf9f9;background-image: none;is_customized: 1;" >
		<div class="wsite-section-content">
			
          <div class="container">
            <div class="banner">
				<div class="wsite-section-elements">
					<h2 class="wsite-content-title"><font color="#2a2a2a">Materials and Methods</font></h2>
				</div>
			</div>
          </div>
      
		</div>
		<div class=""></div>
	</div>
</div>

</div>

    </div>

    <div class="main-wrap">
      <div id="wsite-content" class="wsite-elements wsite-not-footer">
	<div class="wsite-section-wrap">
	<div class="wsite-section wsite-body-section wsite-background-13"  >
		<div class="wsite-section-content">
          <div class="container">
			<div class="wsite-section-elements">
				<div><div class="wsite-image wsite-image-border-none " style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
<a>
<img src="uploads/4/8/6/1/48611635/overall_orig.jpg" alt="Picture" style="width:auto;max-width:100%" />
</a>
<div style="display:block;font-size:90%"></div>
</div></div>

<div class="paragraph" style="text-align:justify;"><span><span>MREable takes in inertial data in real-time from eSense earable sensors, pre-processes and inputs the inertial frames into a trained regressor and receives the head-pose as the output. The head-pose data is then fed into a head-related transfer function (HRTF) in the appropriate form in the desired platform (elevation and azimuth angles in the VR/MR platform), which outputs binaural/spatial audio to the earables based on the head-pose.</span></span></div>

<div><div style="height: 0px; overflow: hidden; width: 100%;"></div>
<hr class="styled-hr" style="width:100%;"></hr>
<div style="height: 30px; overflow: hidden; width: 100%;"></div></div>

<h2 class="wsite-content-title">Data Collection Framework:</h2>

<div class="wsite-spacer" style="height:10px;"></div>

<div class="paragraph" style="text-align:justify;">To collect head-pose training data, a subject is instructed to sit at a particular position (called the origin, say (<em>x</em>'<em>,y',z')</em>)&nbsp;in the experimental testbed with the appropriate earables worn on both ears. The left earable, which houses the 6DOF IMU, transmits inertial data to an android app developed for mining eSense IMU data. The right earable is used to record sound being emanated from a speaker with the centroid at a fixed point (<em>x'',y'',z''</em>). In addition, the subject is asked to wear a hat with OptiTrack IR markers mounted in a rigid body configuration. The subject is then asked to look at several marked points in the 3D space in the experimental testbed with respect to&nbsp;<em>(x'',y'',z''</em>), i.e. the user initially fixes his head towards the origin and then moves his head towards a particular point <em>(x''',y''',z''')</em>.&#8203; Two types of transitions need to be taken into account:<br />&#8203;<ul><li>Head movements from origin to marked point and vice versa.</li><li>Head movements from origin to multiple marked points and vice versa.</li></ul><br />In the experimental testbed, there are 27 marked points and we collect 34 (13+21) distinct head-pose inertial frames per subject. Each user keeps his gaze fixed at the marked points for at least 1/2 seconds.<br /><br />&#8203;The OptiTrack system consists of 6 IR cameras and serves as the ground truth for the eSense inertial data, with a screen recorder application recording visual cues and the MotiveTracker software recording inertial data of the rigid body formed by the markers. In order to synchronize all of the data collection systems, timestamping is used such that the frameworks synchronize time with their respective local system clocks already synchronized with time from the Internet NTP servers. To help simplify things further, the user nods his head in a certain motion (we call it "calibration nod") while saying "start" before providing the head-pose readings.<br /><br />The data collection guide for subjects is available in the Github repository. The subjects were asked to do the following in part 1 of the experiment:<ul><li>Wear the cap. Inform the collector to start data collection. Collector starts the e-Sense android app, starts the binaural audio playing on the speakers, starts audio recorder and finally starts the Optitrack system.&nbsp;</li><li>When collector says "START", nod your head horizontally in &ldquo;No&rdquo; motion three times and vertically in &ldquo;Yes&rdquo; motion three times (this is to sync the OptiTrack system with the e-sense system). Collector will show how to do it efficiently. Say the word &ldquo;Start&rdquo; when you start nodding your head.</li><li>Start with your eyes fixed at the origin for 2 seconds. (step 1)</li><li>Move your head towards a target. (step 2)</li><li>Keep your head fixed at the target for 2 seconds. (step 3)</li><li>Move your head back to origin. (step 4)</li><li>Repeat the above steps (steps 1 to 4) for the following transitions (origin &ndash; target &ndash; origin). If you can&rsquo;t see a number, make sure your point it out to the data collector before starting the experiment.</li><li>Once you&rsquo;re done (make sure your head is fixed towards origin, inform the data collector without moving your head). Don&rsquo;t remove cap or earables. Collector will stop data collection.</li></ul><br />Part 2 of the experiment followed similarly, except subjects moved their head from origin to first target, first target to second target and then back to origin. For the last 2/3 subjects, we used a laser pointer to help subjects identify targets.<br /><br />In order to characterize the position of each marked point in the 3D experimental testbed, we use a Leica Disto X3 laser rangefinder and a smartphone compass to obtain the distance, azimuth and elevation angles of the targets from the point the subject sits. It is important to note that since height of each subject varies, it is important to designate the azimuth and elevation angles of each point with respect to the origin separately for each subject. We keep record of the height of the ears of the subject from the Optitrack origin rigid body, their natural height, weight and age. We have found out that if we set the rangefinder at the average height of the ears of the subject from the Optitrack rigid body (~15 inches) of all subjects, then the elevation angles is ~0 degrees when the rangefinder points directly towards the origin.<br /><br />In addition, we also aim to create a HAR dataset using the earable sensors. Using the same subjects and an optical camera for ground truth, we have created a database of several fine-grained activities such as activities relevant to body and limb motions pertinent to VR/MR context. Such a dataset maybe useful for future research where the user is able to move physically in a MR context rather than being bounded to head-movement. The following activities have ben recorded:<br /><br />1. Walking 2. Jogging 3. Jumping 4. Standing 5. Turning Left 6. Turning Right 7. Sitting 8. Laying 9. Falling<br /><br />The Optitrack data is recorded as .tak files, while the earable inertial data is recorded as .txt file. The audio data is recorded in .mp3 format and the camera data were recorded as video files.<br /><br />The earable parameters were set as follows:<ul><li>Range of accelerometer: +- 2g, gyroscope: +- 500 deg/S</li><li>Advertisement and connection intervals: 45-55 mS and 20-30 mS respectively</li><li>Sampling rate: 100 Hz.</li><li>Low pass filter: Enabled for both accelerometer and gyroscope, cutoff frequency set at 5 Hz for both.</li></ul></div>

<div><div class="wsite-image wsite-image-border-none " style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
<a>
<img src="uploads/4/8/6/1/48611635/imag1-copy_orig.jpg" alt="Picture" style="width:auto;max-width:100%" />
</a>
<div style="display:block;font-size:90%"></div>
</div></div>

<div class="paragraph" style="text-align:center;">Figure: Experimental setup for earable, Optitrack and audio data collection.</div>

<div><div class="wsite-image wsite-image-border-none " style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
<a>
<img src="uploads/4/8/6/1/48611635/untitled_orig.jpg" alt="Picture" style="width:auto;max-width:100%" />
</a>
<div style="display:block;font-size:90%"></div>
</div></div>

<div class="paragraph" style="text-align:center;">Figure: Targets characterized in Cartesian Coordinates (dimensions are given in inches). Concrete azimuth, elevation and ranges are available in the Github repository.</div>

<div><div style="height: 0px; overflow: hidden; width: 100%;"></div>
<hr class="styled-hr" style="width:100%;"></hr>
<div style="height: 30px; overflow: hidden; width: 100%;"></div></div>

<h2 class="wsite-content-title">Preprocessing, Training and HRTF:&nbsp;</h2>

<div class="paragraph" style="text-align:justify;"><span style="color:rgb(42, 42, 42)">Filtering, windowing and labeling of the data were done manually, correlating visual Optitrack cues with gyroscope sensor data plots as well as audio data for assistance. Manual correlation was applied for four reasons:</span><ul><li><span style="color:rgb(42, 42, 42)">Some subjects made mistakes during takes, either missing designated targets, overshooting their head movement or looking at wrong targets.</span></li><li><span style="color:rgb(42, 42, 42)">Some subjects didn't move their head at all while looking at targets very close to the origin (targets 1-6 for example). They were not captured by Optitrack, let alone the earable.</span></li><li><span style="color:rgb(42, 42, 42)">The sampling rate of earable data collection was not constant and jumped erratically between 1 Hz to 100 Hz due to loss in LoS between earable and mobile phone, BLE channel latency, improper advertisement and connection intervals of the earable as well as smartphone's performance bottleneck.</span></li><li><span style="color:rgb(42, 42, 42)">Sometimes, the app didn't collect data at all (missing data).</span></li></ul><br /><span style="color:rgb(42, 42, 42)">The inertial data was plotted in MATLAB and the following inferences were made:</span><ul><li><span style="color:rgb(42, 42, 42)">When user moves his head left and right, gyroscope's x and y axis provides negative and positive values respectively (unless a subject decides to wear the earable in a completely&nbsp;erroneous manner, which happened in case of one subject. It is important to note that the earable goes in only one way)</span></li><li><span style="color:rgb(42, 42, 42)">When user moves his head up and down, gyroscope's z axis provides negative and positive values respectively (regardless of how the user wears the earable).</span></li></ul><br /><span style="color:rgb(42, 42, 42)">A single head rotation on the gyroscope-time plot essentially consists of a triangular/bell curved shape peak, with the rate of change of the angular velocity as well as the angular velocity being proportional to how fast the user moves his head (faster = thinner and taller peak, slower = thicker and smaller peak). In case of head movements from a single target and back, one will observe two opposite peaks on the gyroscope plot. For dual targets, one will observe groups of three peaks.</span></div>

<div><div class="wsite-image wsite-image-border-none " style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
<a>
<img src="uploads/4/8/6/1/48611635/sampleplot_orig.jpg" alt="Picture" style="width:auto;max-width:100%" />
</a>
<div style="display:block;font-size:90%"></div>
</div></div>

<div class="paragraph" style="text-align:center;">Figure: Sample plot of angular velocity (x plane) vs time for origin-target-origin take. The head movements are identified and numbered in the graph visually here without the need for aid of ground truth data from Optitrack.</div>

<div class="paragraph" style="text-align:justify;">After slicing, cleaning and labeling the headpose data from all subjects. 1266 inertial frames were obtained. 356 of these frames were captured for origin-target-origin takes and 910 of these frames were captured for origin-target1-target2-origin takes. 607 of the 910 frames correspond to origin-target1 and target2-origin frames while the rest 303 frames correspond to target1-target2 frames. The sliced headpose data is available in the Github repository.<br /><br />&#8203;<br /><span style="color:rgb(42, 42, 42)">734 out of 1266 frames were grouped into bins of 20 degrees due to the data being extremely noisy, essentially converting the regression problem into a classification problem.</span><span style="color:rgb(42, 42, 42)">&nbsp;The angular ranges are as follows:&nbsp;</span><span style="color:rgb(42, 42, 42)">Elevation: [-140, 180] (16 classes) Azimuth: [-140, 140] (14 classes). Extracted features (provided in "Results" page) include integration, skewness, kurtosis, norm, variation, time-window and sum-over-time.&nbsp;The data is fed into a deep learning model (as well as other classifiers for performance evaluation) to train the model and once the model is trained, during the live system stage, the inertial value is filtered using the model to predict the head pose estimation.&nbsp;The deep learning model will be supervised and based on previous work we wanted to use RNN to exploit the time-based data. The data will have a temporal correlation as it is a time sequence, so to use this information a model like RNN should be preferred. The models were implemented using a combination of MATLAB and Tensorflow initially and moved to Tensorflow Lite to deploy on mobile devices. However, after performance evaluation, we observed that XGBoost performs better than neural networks.</span><br /><br /><br /><span style="color:rgb(42, 42, 42)">The head pose estimation is presented in the form of altitude and elevation and direction appropriate to the HRTF. The HRTF is then interpolated to the point specified by the IMU and filters are made for left and right audio.&nbsp;HRTF or head related transfer function is the response of how human ear perceives the location of the sound. A pair of two HRTF functions is used to generate binaural audio (the way human ear perceives the differential sounds from source in two ears). The HRTF is defined as the ratio of the Fourier transform of the sound pressure developed at the ear to the Fourier transform of the sound pressure developed at the location of the center of the listener&rsquo;s head with the listener absent. The HRTF is a function of the elevation and the azimuthal angle relative to the sound source apart from parameters like distance to the speaker and sometimes diameter of the head. The HRTF dataset is usually available for a wide range of points developed using in ear microphones and multiple test users. In our project we use the ARI HRTF database which has the data points for 1550 positions of over 200 subjects. The resolution is 2.5 degrees for azimuthal range of (-45 to 45 degrees) and a resolution of 5 degrees outside the space, and at fixed elevations between -30 degrees to 80 degrees. The HRTF for a point outside the range is found using interpolation and MATLAB provides a function for this.<br /><br />In order to achieve our first milestone, the trained model shall be a classifier which will predict the final head pose based on the input sequence (live input stream). The predicted head pose then will be fed to MATLAB. For spatial audio generation, the interpolated HRTF is calculated at the position of the head tracked. Using the HRTF two FIR Filters are made for each channel of audio. The audio signal is then convolved with the filter to get the final binaural audio from the mono or stereo audio file. We have already written software that can mine earable data, provide it to a head-pose estimator (a complementary Kalman Filter for time being) and generate spatial audio from a static sound source.</span></div>

<div><div style="height: 0px; overflow: hidden; width: 100%;"></div>
<hr class="styled-hr" style="width:100%;"></hr>
<div style="height: 30px; overflow: hidden; width: 100%;"></div></div>

<h2 class="wsite-content-title">Integrating Inertial Framework and Spatial Audio with VR/MR Platforms:</h2>

<div class="wsite-spacer" style="height:10px;"></div>

<div class="paragraph" style="text-align:justify;"><span><span>To avoid blurring of audio clarity during user motion and the high cost of 360&deg; ambisonic microphones, we use object-oriented methods to build our audio environment where all sound sources can be rendered in real-time.&nbsp;<br /><br />&#8203;</span></span><span><span>We first build the fundamental visual virtual environment in Unity, with reasonable metrics and coordinates of objects, because a visual interface bundled with audio is more user-friendly and convenient for troubleshooting during development. On the GAudioWorks platform, we add sound sources with azimuth (lateral position), elevation (height position) and distance (shall not come from IMU but be managed programmatically) from a first-person perspective, which is ideal binaural effect testing in a static scene.&nbsp;</span></span><br /><br /></div>

<div><div class="wsite-image wsite-image-border-none " style="padding-top:10px;padding-bottom:10px;margin-left:0;margin-right:0;text-align:center">
<a>
<img src="uploads/4/8/6/1/48611635/unity-screenshot_orig.jpg" alt="Picture" style="width:auto;max-width:100%" />
</a>
<div style="display:block;font-size:90%"></div>
</div></div>

<div class="paragraph" style="text-align:center;">Figure: Developed spatial audio generation app in Unity.</div>

<div class="paragraph" style="text-align:justify;"><span><span>We have developed a sound test system based on the 3D kart template on Unity platform.&nbsp;The spatial effect (Binaural effect, Doppler effect) of the sound source changes with the game's hero movement and it has been achieved based on sound dynamics theory as discussed earlier. With eyes closed, users can still clearly distinguish the location of the source with the help of our spatial audio effect.&nbsp;&nbsp;In the demo, the role&rsquo;s position &amp; orientation is controlled by keyboard. We will move on to implement inputs with earable at the last stage.<br /><br />One of the challenges encountered is that the Oculus integration package, which is essential to Samsung Gear VR application development in Unity, no longer supports Gear VR from September 2019. They also deleted the older version of online download resources. Additionally, we need to figure out how to wrap the calculation result of the earable classifiers and use it as the input of games in real time with decent accuracy.&nbsp;&nbsp;We also need to look for a well-configured VR development platform (or buy older development resources from a third party), or temporarily turn from Gear VR to a simpler demo with phone semi-VR interface and hand-made cardboard. After all, vision part is less necessary than audio part in this project.</span></span><br /><br /><span style="color:rgb(42, 42, 42)">&#8203;</span><br /><span style="color:rgb(42, 42, 42)">We aim to use AudioListener and the AudioSource to capture the distance and angles. Besides, we utilize MRTK2 (Mixed Reality Toolkit 2) provided by Unity, which enables a richer human-computer interface, including the user&rsquo;s location and orientation rendered via IMU in eSense earables. What we do is integrate the user data into the modulation and regulation of the gains of the left and right ear contributions. After successful implementation on a VR headset, we adapt the user interface suitable for eSense Earable and make it possible to handle the system with only earables and smartphone.</span></div>

<div class="paragraph" style="text-align:center;"><font size="2"><span style="color:rgb(42, 42, 42); font-weight:bold">Project by&nbsp;</span><a href="http://nesl.ee.ucla.edu/people/511" target="_blank">Swapnil Sayan Saha</a><span style="color:rgb(42, 42, 42); font-weight:bold">,&nbsp;</span><a href="http://nesl.ee.ucla.edu/people/499" target="_blank">Siyou Pei</a><span style="color:rgb(42, 42, 42); font-weight:bold">&nbsp;and Vivek Jain for ECE M202A (Fall 2019) at UCLA under supervision of Dr.&nbsp;</span><a href="http://nesl.ee.ucla.edu/people/1" target="_blank">Mani B. Srivastava</a><span style="color:rgb(42, 42, 42); font-weight:bold">.<br />&#8203;</span><br /><span style="color:rgb(42, 42, 42); font-weight:bold">Site powered by&nbsp;</span><a href="https://github.com" target="_blank">Github</a><span style="color:rgb(42, 42, 42); font-weight:bold">&nbsp;and&nbsp;</span><a href="https://www.weebly.com" target="_blank">Weebly.</a></font></div>
			</div>
		</div>
      </div>

	</div>
</div>

</div>

    </div>

    <div class="footer-wrap">
        <div class="footer">Create a <a target="_top" href="http://www.weebly.com/">free web site</a> with <a target="_top" href="http://www.weebly.com/" title="free web site">Weebly</a></div>
    </div>
  </div>

  <div class="nav mobile-nav">
    <a class="hamburger" aria-label="Menu" href="#"><span></span></a>
    <ul class="wsite-menu-default">
    		<li id="pg882454809154185041" class="wsite-menu-item-wrap">
    			<a
    						href="project-abstract.html"
    				class="wsite-menu-item"
    				>
    				Project Abstract
    			</a>
    			
    		</li>
    		<li id="active" class="wsite-menu-item-wrap">
    			<a
    						href="materials-and-methods.html"
    				class="wsite-menu-item"
    				>
    				Materials and Methods
    			</a>
    			
    		</li>
    		<li id="pg990999752696982730" class="wsite-menu-item-wrap">
    			<a
    						href="results.html"
    				class="wsite-menu-item"
    				>
    				Results
    			</a>
    			
    		</li>
    		<li id="pg595281588527961028" class="wsite-menu-item-wrap">
    			<a
    						href="conclusion-and-future-work.html"
    				class="wsite-menu-item"
    				>
    				Conclusion and Future Work
    			</a>
    			
    		</li>
    		<li id="pg905329364918407754" class="wsite-menu-item-wrap">
    			<a
    						href="related-work.html"
    				class="wsite-menu-item"
    				>
    				Related Work
    			</a>
    			
    		</li>
    		<li id="pg500750823166447332" class="wsite-menu-item-wrap">
    			<a
    						href="references.html"
    				class="wsite-menu-item"
    				>
    				References
    			</a>
    			
    		</li>
    </ul>
  </div>

  <script>
    (function(d) {
      var config = {
        kitId: 'nxe1ajf',
        scriptTimeout: 3000,
        async: true
      },
      h=d.documentElement,t=setTimeout(function(){h.className=h.className.replace(/\bwf-loading\b/g,"")+" wf-inactive";},config.scriptTimeout),tk=d.createElement("script"),f=false,s=d.getElementsByTagName("script")[0],a;h.className+=" wf-loading";tk.src='https://use.typekit.net/'+config.kitId+'.js';tk.async=true;tk.onload=tk.onreadystatechange=function(){a=this.readyState;if(f||a&&a!="complete"&&a!="loaded")return;f=true;clearTimeout(t);try{Typekit.load(config)}catch(e){}};s.parentNode.insertBefore(tk,s)
    })(document);
  </script>

	<script type="text/javascript" src="files/theme/plugins.js"></script>
  <script type="text/javascript" src="files/theme/custom.js"></script>
    <div id="customer-accounts-app"></div>
    <script src="http://cdn2.editmysite.com/js/site/main-customer-accounts-site.js?buildTime=1234"></script>

		
	</body>
</html>
